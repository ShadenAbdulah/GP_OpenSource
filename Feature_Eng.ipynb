{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Extract 30 feature from 6 raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'ZL_trace' \n",
    "# [ZL_trace, ZL_predict, PL_trace, PL_predict]\n",
    "\n",
    "df = f'Datasets/Full_DS/{task_name}.csv'\n",
    "\n",
    "output = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wacom sitting\n",
    "df['ClientX'] = (df['ClientX'] * (3840 / 2000))\n",
    "df['ClientY'] = (df['ClientY'] * (2160 / 1200))\n",
    "\n",
    "df['Pressure'] = df['Pressure'] * 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Features Sitting\n",
    "timeSpent = max(df['timestamp']) - min(df['timestamp'])\n",
    "\n",
    "df['TiltX'] = df['TiltX'] + 90\n",
    "df['TiltY'] = df['TiltY'] + 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peaks & Valleys Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks(series):\n",
    "    peaks = []\n",
    "    for i in range(1, len(series) - 1):\n",
    "        if series.iloc[i] > series.iloc[i - 1] and series.iloc[i] > series.iloc[i + 1]:\n",
    "            peaks.append(i)\n",
    "    return peaks\n",
    "\n",
    "def find_valleys(series):\n",
    "    valleys = []\n",
    "    for i in range(1, len(series) - 1):\n",
    "        if series.iloc[i] < series.iloc[i - 1] and series.iloc[i] < series.iloc[i + 1]:\n",
    "            valleys.append(i)\n",
    "    return valleys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Width = (max(df['ClientX']) - min(df['ClientX']))\n",
    "Height = (max(df['ClientY']) - min(df['ClientY']))\n",
    "\n",
    "\n",
    "output.at[0, 'Width']= Width\n",
    "output.at[0, 'Height']= Height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distances = []\n",
    "\n",
    "for i in range(1, len(df)):\n",
    "    x = df['ClientX'][i] - df['ClientX'][i-1]\n",
    "    y = df['ClientY'][i] - df['ClientY'][i-1]\n",
    "\n",
    "    sqrt = math.sqrt((x**2) + (y**2))\n",
    "    euclidean_distances.append(sqrt)\n",
    "\n",
    "Length = sum(euclidean_distances)\n",
    "output.at[0, 'Length']= Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features 4, 5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_velocities(exper):\n",
    "    euclidean_distances = []\n",
    "    velocities = []\n",
    "\n",
    "    for i in range(1, len(exper)):\n",
    "        x = exper['ClientX'][i] - exper['ClientX'][i-1]\n",
    "        y = exper['ClientY'][i] - exper['ClientY'][i-1]\n",
    "\n",
    "        displacement = math.sqrt((x**2) + (y**2))\n",
    "        euclidean_distances.append(displacement)\n",
    "\n",
    "        delta_time = exper['timestamp'][i] - exper['timestamp'][i-1]\n",
    "\n",
    "        if delta_time > 0:\n",
    "            Velocity = displacement / delta_time\n",
    "            velocities.append(Velocity)\n",
    "        else:\n",
    "            velocities.append(0)\n",
    "\n",
    "    return velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocities = pd.Series(calculate_velocities(df))\n",
    "Velocity = velocities.mean()\n",
    "\n",
    "P_max_V = max(velocities) * 3.3\n",
    "P_min_V =  min(vel for vel in velocities if vel > 0) * 3.3\n",
    "\n",
    "output.at[0, 'Velocity']= Velocity\n",
    "\n",
    "output.at[0, 'P_max_V']= P_max_V\n",
    "output.at[0, 'P_min_V']= P_min_V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features 7, 8, 9, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accelerations(exper):\n",
    "    accelerations = []\n",
    "    previous_Velocity = 0\n",
    "\n",
    "    for i in range(1, len(exper)):\n",
    "        x = exper['ClientX'][i] - exper['ClientX'][i-1]\n",
    "        y = exper['ClientY'][i] - exper['ClientY'][i-1]\n",
    "        displacement = math.sqrt((x**2) + (y**2))\n",
    "\n",
    "        delta_time = exper['timestamp'][i] - exper['timestamp'][i-1]\n",
    "\n",
    "        if delta_time > 0:\n",
    "            Velocity = displacement / delta_time\n",
    "            delta_Velocity = Velocity - previous_Velocity\n",
    "            acceleration = abs(delta_Velocity) / delta_time\n",
    "            accelerations.append(acceleration)\n",
    "\n",
    "            previous_Velocity = Velocity\n",
    "        else:\n",
    "            accelerations.append(0)\n",
    "\n",
    "    return accelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerations = pd.Series(calculate_accelerations(df))\n",
    "P_max_A= max(accelerations) * 3.3\n",
    "P_min_A = min(abs(acc) for acc in accelerations if acc > 0) * 3.3\n",
    "\n",
    "output.at[0, 'P_max_A']= P_max_A\n",
    "output.at[0, 'P_min_A']= P_min_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA_mean_H = df['TiltX'].mean()\n",
    "GA_mean_V = df['TiltY'].mean()\n",
    "\n",
    "output.at[0, 'GA_mean_H']= GA_mean_H\n",
    "output.at[0, 'GA_mean_V']= GA_mean_V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features 11, 12, 13, 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature 11\n",
    "GA_SD_H = df['TiltX'].std()\n",
    "output.at[0, 'GA_SD_H']= GA_SD_H\n",
    "\n",
    "# Feature 12\n",
    "GA_SD_V = df['TiltY'].std()\n",
    "output.at[0, 'GA_SD_V']= GA_SD_V\n",
    "\n",
    "#Feature 13\n",
    "PressureMean = df['Pressure'].mean()\n",
    "output.at[0, 'PressureMean']= PressureMean\n",
    "\n",
    "#Feature 14\n",
    "PressureSD = stat.stdev(df['Pressure'])\n",
    "output.at[0, 'PressureSD']= PressureSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features 15, 16, 17, 18, 19, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pressure_diff'] = df['Pressure'].diff()\n",
    "df['Time_diff'] = df['timestamp'].diff()\n",
    "\n",
    "df['Pressure_change_rate'] = df.apply(\n",
    "    lambda row: row['Pressure_diff'] / row['Time_diff'] if row['Time_diff'] != 0 and row['Pressure_diff'] >0 else None, axis=1\n",
    ")\n",
    "\n",
    "df['Positive_change_rate'] = df.apply(\n",
    "    lambda row: row['Pressure_change_rate'] if row['Pressure_change_rate'] > 0 else 0, axis=1\n",
    ")\n",
    "df['Negative_change_rate'] = df.apply(\n",
    "    lambda row: row['Pressure_change_rate'] if row['Pressure_change_rate'] < 0 else 0, axis=1\n",
    ")\n",
    "\n",
    "positive_changes = df['Positive_change_rate'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAvgPos = stat.mean(positive_changes)  # Feature 15: Mean of positive changes\n",
    "PCSDPos = stat.stdev(positive_changes)  # Feature 16: Standard deviation of positive changes\n",
    "PCMax = max(positive_changes)\n",
    "\n",
    "output.at[0, 'PCAvgPos']= PCAvgPos\n",
    "output.at[0, 'PCSDPos']= PCSDPos\n",
    "output.at[0, 'PCMax']= PCMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAvgNeg = stat.mean(positive_changes)  # Feature 18: Mean of negative changes\n",
    "PCSDNeg = stat.stdev(positive_changes)  # Feature 19: Standard deviation of negative changes\n",
    "PCMin = max(positive_changes) # Feature 20\n",
    "\n",
    "output.at[0, 'PCAvgNeg']= PCAvgNeg\n",
    "output.at[0, 'PCSDNeg']= PCSDNeg\n",
    "output.at[0, 'PCMin']= PCMin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(x1, y1, x2, y2, x3, y3):\n",
    "    vector1 = np.array([x1 - x2, y1 - y2])\n",
    "    vector2 = np.array([x3 - x2, y3 - y2])\n",
    "\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    magnitude_product = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
    "\n",
    "    if magnitude_product == 0: return 0\n",
    "\n",
    "    cosine_angle = dot_product / magnitude_product\n",
    "    angle_rad = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    return angle_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_feature(row1, row2, row3):\n",
    "    x1, y1 = row1['TiltX'], row1['TiltY']\n",
    "    x2, y2 = row2['TiltX'], row2['TiltY']\n",
    "    x3, y3 = row3['TiltX'], row3['TiltY']\n",
    "\n",
    "    triangle_angle = calculate_angle(x1, y1, x2, y2, x3, y3)\n",
    "    square_angle = 90\n",
    "\n",
    "    error = square_angle - triangle_angle\n",
    "\n",
    "    return error < 0, row2['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error = 0\n",
    "\n",
    "for i in range(0, len(df) - 2, 3):\n",
    "    row1 = df.iloc[i]\n",
    "    row2 = df.iloc[i + 1]\n",
    "    row3 = df.iloc[i + 2]\n",
    "    error_feature, timestamp = compute_error_feature(row1, row2, row3)\n",
    "\n",
    "    if error_feature: Error += 1\n",
    "\n",
    "output.at[0, 'Error']= Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "press = df['Pressure']\n",
    "press = pd.concat([press, pd.Series([0])], ignore_index=True)\n",
    "\n",
    "valleys = find_valleys(press)\n",
    "Pressure_valleys = df['Pressure'].iloc[valleys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Pressure_valleys.empty:\n",
    "    PeakpresMean = 0\n",
    "else:\n",
    "    PeakpresMean = (Pressure_valleys.mean())\n",
    "\n",
    "output.at[0, 'PeakpresMean']= PeakpresMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_timestamps = []\n",
    "\n",
    "for i in range(0, len(df) - 2, 3):\n",
    "    row1 = df.iloc[i]\n",
    "    row2 = df.iloc[i + 1]\n",
    "    row3 = df.iloc[i + 2]\n",
    "    error_feature, timestamp = compute_error_feature(row1, row2, row3)\n",
    "\n",
    "    if error_feature:\n",
    "        error_timestamps.append(timestamp)\n",
    "\n",
    "# Compute the mean of the error timestamps if there are any\n",
    "if error_timestamps:\n",
    "    base_timestamp = min(error_timestamps)\n",
    "    error_timestamps_ms = [(t - base_timestamp) for t in error_timestamps]\n",
    "    mean_timestamp = np.mean(error_timestamps_ms)\n",
    "    output.at[0, 'ErrorStopTime'] = mean_timestamp\n",
    "else:\n",
    "    output.at[0, 'ErrorStopTime'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TiltAngle'] = np.degrees(np.arctan2(df['TiltY'], df['TiltX']))\n",
    "\n",
    "df['TiltAngle'].fillna(value=0, inplace=True)\n",
    "\n",
    "anglepeaks = find_peaks(df['TiltAngle'])\n",
    "anglevalleys = find_valleys(df['TiltAngle'])\n",
    "\n",
    "mean_angle_at_peaks = df['TiltAngle'].iloc[anglepeaks].mean() if len(anglepeaks) > 0 else 0\n",
    "mean_angle_at_valleys = df['TiltAngle'].iloc[anglevalleys].mean() if len(anglevalleys) > 0 else 0\n",
    "\n",
    "AngleMean = np.mean([mean_angle_at_peaks, mean_angle_at_valleys])\n",
    "\n",
    "output.at[0, 'AngleMean'] = AngleMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleVar = df['Pressure'].var()\n",
    "output.at[0, 'AngleVar'] = AngleVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features 26, 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = df.filter(['ClientX', 'ClientY', 'TiltX', 'TiltY', 'Pressure', 'timestamp'])\n",
    "correlation_matrix = raw_data.corr()\n",
    "sorted_correlations = correlation_matrix.abs().unstack().sort_values(ascending=False)\n",
    "top_pairs = sorted_correlations[sorted_correlations < 1].head(1).index\n",
    "\n",
    "col1, col2 = top_pairs[0]\n",
    "x = np.array(df[col1])\n",
    "y = np.array(df[col2])\n",
    "\n",
    "ReglineSlope, ReglineIntercept = np.polyfit(x, y, 1)\n",
    "\n",
    "output.at[0, 'ReglineSlope']= ReglineSlope\n",
    "output.at[0, 'ReglineIntercept']= ReglineIntercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vpeaks = find_peaks(velocities)\n",
    "Vvalleys = find_valleys(velocities)\n",
    "\n",
    "velocities_at_peaks = velocities.iloc[Vpeaks]\n",
    "velocities_at_valleys = velocities.iloc[Vvalleys]\n",
    "\n",
    "if len(velocities_at_peaks) == 0 or timeSpent == 0: LoopCount = timeSpent\n",
    "else: LoopCount = timeSpent / len(velocities_at_peaks)\n",
    "\n",
    "output.at[0, 'LoopCount']= LoopCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if velocities_at_peaks.empty:\n",
    "    mean_Velocity_at_peaks = 0\n",
    "else:\n",
    "    mean_Velocity_at_peaks = velocities_at_peaks.mean()\n",
    "\n",
    "if velocities_at_valleys.empty:\n",
    "    mean_Velocity_at_valleys = 0\n",
    "else:\n",
    "    mean_Velocity_at_valleys = velocities_at_valleys.mean()\n",
    "\n",
    "AngleSpeed = np.mean([mean_Velocity_at_peaks, mean_Velocity_at_valleys])\n",
    "\n",
    "output.at[0, 'AngleSpeed']= AngleSpeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Error == 0 or len(velocities_at_peaks) == 0:\n",
    "    ErrorRate = 0\n",
    "else:\n",
    "    ErrorRate = abs(Error/len(velocities_at_peaks))\n",
    "\n",
    "output.at[0, 'ErrorRate']= ErrorRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Features\n",
    "\n",
    "from 31 to 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StrokeDurationArray = df[df['StrokeDuration'] != 0]\n",
    "Stroke_Duration_mean = stat.mean(StrokeDurationArray['StrokeDuration'])\n",
    "output.at[0, 'Stroke_Duration_mean']= Stroke_Duration_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stroke_Durations = sum(StrokeDurationArray['StrokeDuration'])\n",
    "On_Paper_Time = Stroke_Durations\n",
    "output.at[0, 'On_Paper_Time']= On_Paper_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In_Air_Time = (timeSpent - On_Paper_Time)\n",
    "output.at[0, 'In_Air_Time']= In_Air_Time"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
